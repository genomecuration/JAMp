= TransDecoder (Find Coding Regions Within Transcripts) =

TransDecoder identifies candidate coding regions within transcript sequences, such as those generated by de novo RNA-Seq transcript assembly using Trinity, or constructed based on RNA-Seq alignments to the genome using Tophat and Cufflinks.

TransDecoder identifies likely coding sequences based on the following criteria:

- a minimum length open reading frame (ORF) is found in a transcript sequence

- a log-likelihood score similar to what is computed by the GeneID software is > 0.

- the above coding score is greatest when the ORF is scored in the 1st reading frame as compared to scores in the other 5 reading frames.

- if a candidate ORF is found fully encapsulated by the coordinates of another candidate ORF, the longer one is reported.  However, a single transcript can report multiple ORFs (allowing for operons, chimeras, etc).

- *optional* the putative peptide has a match to a Pfam domain above the noise cutoff score.

The software is primarily maintained by http://www.broadinstitute.org/~bhaas/[Brian Haas] at the http://broadinstitute.org[Broad Institute] and http://tiny.cc/alexie_pap_csiro/[Alexie Papanicolaou] at the http://www.csiro.au/[Commonwealth Scientific and Industrial Research Organisation] (CSIRO). It is integrated into other related software such as http://trinityrnaseq.sf.net[Trinity], http://pasa.sf.net[PASA], http://evidencemodeler.sf.net[EVidenceModeler], and http://trinotate.sf.net[Trinotate].


== Obtaining TransDecoder ==

The latest release of TransDecoder can be found http://sourceforge.net/projects/transdecoder/[here].

== Running TransDecoder ==

=== Predicting coding regions from a transcript fasta file ===

The 'TransDecoder' utility is run on a fasta file containing the target transcript sequences.  The simplest usage is as follows:

[source,bash]
TransDecoder -t target_transcripts.fasta

If the transcripts are oriented according to the sense strand, then include the -S flag to examine only the top strand.  Full usage info is below.

The script generates several output files, which are described below, but the final set of candidate coding regions can be found as files '*.transdecoder.*' where extensions include .pep, .cds, .gff3, and .bed


=== Starting from a genome-based transcript structure GTF file (eg. cufflinks) ===

The process here is identical to the above with the exception that we must first generate a fasta file corresponding to the transcript sequences, and in the end, we recompute a genome annotation file in GFF3 format that describes the predicted coding regions in the context of the genome.

First, convert the transcript structure GTF file to an alignment-GFF3 formatted file (this is done only because our processes operate on gff3 rather than the starting gtf file - nothing of great consequence).  Convert gtf to alignment-gff3 like so, using cufflinks GTF output as an example:

[source,bash]
util/cufflinks_gtf_to_alignment_gff3.pl transcripts.gtf > transcripts.gff3


Next, construct the transcript fasta file using the genome and the transcripts.gff3 file like so:

[source,bash]
util/cufflinks_gtf_genome_to_cdna_fasta.pl transcripts.gtf test.genome.fasta > transcripts.fasta 

Now, run the process described above to generate your best candidate ORF predictions:

[source,bash]
TransDecoder -t transcripts.fasta

And finally, generate a genome-based coding region annotation file:

[source,bash]
cdna_alignment_orf_to_genome_orf.pl transcripts.fasta.transdecoder.gff3 transcripts.gff3 transcripts.fasta > transcripts.fasta.transdecoder.genome.gff3


== Sample data and execution ==

The sample_data/ directory includes a 'runMe.sh' script that you can execute to demonstrate the entire process, starting from a cufflinks GTF file. Note, the typical use-case for TransDecoder is starting from a fasta file containing target 'Transcripts', however, in the case of genome analysis, transcripts are often inferred from annotation coordinates, such as in this Cufflinks GTF formatted file.  In this example, transcript sequences are reconstructed based on the GTF annotation coordinates, and then TransDecoder is executed on that fasta file.  We include an additional utility for converting the transcript ORF coordinates into genome-coordinates so these regions can be examined in the genomic context.

== Output files explained ==

A temporary directory (ex. transdecoder.tmp.nopfam) is created to run and store intermediate parts of the pipeline, and contains:

 longest_orfs.pep   : all ORFs meeting the minimum length criteria, regardless of coding potential.
 longest_orfs.gff3  : positions of all ORFs as found in the target transcripts
 longest_orfs.cds   : the nucleotide coding sequence for all detected ORFs

 longest_orfs.cds.top_500_longest   : the top 500 longest ORFs, used for training a Markov model for coding sequences.

 hexamer.scores                     : log likelihood score for each k-mer  (coding/random)

 longest_orfs.cds.scores            : the log likelihood sum scores for each ORF across each of the 6 reading frames
 longest_orfs.cds.scores.selected   : the accessions of the ORFs that were selected based on the scoring criteria (described at top)
 longest_orfs.cds.best_candidates.gff3               : the positions of the selected ORFs in transcripts


Then, the final outputs are reported in your current working directory:

 transcripts.fasta.transdecoder.pep : peptide sequences for the final candidate ORFs; all shorter candidates within longer ORFs were removed.
 transcripts.fasta.transdecoder.cds  : nucleotide sequences for coding regions of the final candidate ORFs
 transcripts.fasta.transdecoder.gff3 : positions within the target transcripts of the final selected ORFs
 transcripts.fasta.transdecoder.bed  : bed-formatted file describing ORF positions, best for viewing using GenomeView or IGV.


== Including PFAM domain searches as ORF retention criteria ==

To further maximize sensitivity for capturing ORFs that may have functional significance, regardless of coding likelihood score as mentioned above, you can scan all ORFs for PFAM domain hits, and retain all such ORFs as part of the final TransDecoder output.  Run TransDecoder like so:

[source,bash]
TransDecoder -t target_transcripts.fasta --search_pfam /path/to/Pfam-A.hmm

This requires that you have http://hmmer.janelia.org/software[HMMER] installed and available in your PATH setting, and ftp://ftp.sanger.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz[Pfam] downloaded to be searched locally. If you are ok with not using the latest Pfam-A release from the Sanger institute, simply do:

[source,bash]
make prep_pfam

This will download a 'good-to-go' binary (compressed) version of the combined Pfam-A and -B datasets from the http://sourceforge.net/projects/transdecoder/files/Pfam-AB.hmm.bin/download[TransDecoder] site. Using Pfam-B will increase sensitivity for 'non-model' species at the expense of the searches taking a bit longer. The PFAM file on our website was created using the Pfam version that was current on the Modified Date shown on http://sourceforge.net/projects/transdecoder/files/?source=navbar[Transdecoder file listing].

Alternatively, you can create a new one from scratch:

[source,bash]
wget ftp://ftp.sanger.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz ftp://ftp.sanger.ac.uk/pub/databases/Pfam/current_release/Pfam-B.hmm.gz
gunzip -c Pfam-A.hmm.gz Pfam-B.hmm.gz > Pfam-AB.hmm
hmmconvert -b Pfam-AB.hmm > pfam/Pfam-AB.hmm.bin
rm Pfam-A.hmm.gz Pfam-B.hmm.gz Pfam-AB.hmm pfam/Pfam-AB.hmm.bin.*
make prep_pfam

Once either of this step is complete, you have the option of running on another single server (with ParaFly) or submit to a batch system:

=== Stand-alone just use this for eg. 5 CPUs ===

[source,bash]
TransDecoder -t target_transcripts.fasta --reuse --workdir transdecoder --search_pfam /path_to_transdecoder/pfam/Pfam-AB.hmm.bin --CPU 5

=== Using MPI ===

Highly recommended: if you have a computing cluster and MPI installed, you can run TransDecoder using multiple threads with:

[source,bash]
TransDecoder -t target_transcripts.fasta --search_pfam /path/to/Pfam-A.hmm --MPI --CPU number_of_CPUs

==== How to prepare for MPI ====

* MPI is free. First you need the relevant software. We recommend openMPI. You can install it from repositories, e.g. on Debian/Ubuntu: 
 
[source,bash]
apt-get install openmpi-bin

** MPICH2 specific instruction
+
TIP: If you don't use OpenMPI but use mpich2 then use mpiexc start the MPI daemon. You only need to do this once (i.e. if you have done it before and the computer was not restarted, it should be there)
+
[source,bash]
ps -Af|grep $USER|grep mpd # if nothing comes back then:
mpd &

Then you need to re-run make so that FFINDEX is compiled correctly. Finally you need to tell the system where the FFINDEX libraries reside. 
You do this by setting the environmental variable of LD_LIBRARY_PATH to point to your /full_path_to_transdecoder/util/lib64 (obviously replace the full_path_to_transdecoder):
[source,bash]
make
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/full_path_to_transdecoder/util/lib64

You can choose to add this last command to your $HOME/.bashrc file (so it is executed automatically at login), run it manually before using --MPI with Transdecoder or ask your system administrator to do it for you.

==== Batch system on a HPC cluster ====

For high-throughput projects, we recommend the use of a HPC cluster and the use of MPI. We regularly use it with 80-90 nodes on a PBS/Torque batch environment. The example scripts in util/pfam_mpi* are suitable for PBS and with the help of your system administrators, it is straightforward to reconfigure them for other systems (such as the popular LSF/SGI). For this scenario, ask TransDecoder to use a specific working directory, to re-use existing files and stop when the PFAM searches are prepared:

[source,bash]
TransDecoder -t target_transcripts.fasta --search_pfam /path/to/Pfam-A.hmm --MPI --workdir mytransdecoder_output --reuse --prepare_pfam
cd mytransdecoder_output
cp $TRANSDECODER_DIR/util/pfam_mpi.* .  # assuming you have already made any changes that are system-specific
./pfam_mpi.sh   # submits the job

Wait until the run is complete:

[source,bash]
$TRANSDECODER_DIR/util/ffindex_gather.sh longest_orfs.pep_out2    # Tells you if any sequence has not been searched

If something has not been processed (e.g. because walltime expired), resubmit the job; because of ffindex_gather, only sequences not already searched will be run.

[source,bash]
./pfam_mpi.sh
$TRANSDECODER_DIR/util/ffindex_gather.sh longest_orfs.pep_out2    # check again. 

If all sequences have been searched, then an output file without the FFINDEX zero bytes will be produced:

[source,bash]
TransDecoder -t target_transcripts.fasta --search_pfam /path/to/Pfam-A.hmm --MPI --workdir mytransdecoder_output --reuse --pfam_out mytransdecoder_output/longest_orfs.pep_out2.all.db.txt

=== PFAM output ===
	
When TransDecoder is finished, you no longer require the mytransdecoder_output and can safely delete it. Before you do that, feel free to use the pfam_out file for http://trinotate.sf.net[Trinotate] to annotate your protein sequences. Also feel free to use these scripts as templates for other work: we (at CSIRO) routinely use this FFINDEX/MPI system to annotate the protein sequences with a variety of databases: a new software called http://jamps.sf.net[Just_Annotate_My_Proteins] (JAMp) is coming this (Southern) summer to a SourceForge site near you.

== Viewing the ORF predictions in a genome browser ==

http://genomeview.org[GenomeView] or http://www.broadinstitute.org/igv/[IGV] are  recommended for viewing the candidate ORFs in the context of the genome or the transcriptome.  Examples below show GenomeView in this context.

=== Viewing ORFs on target transcripts ===

[source,bash]
java -jar $GENOMEVIEW/genomeview.jar transcripts.fasta transcripts.fasta.transdecoder.bed

If you lack a genome sequence and are working exclusively with the target transcripts, you can load the transcript fasta file and the ORF predictions (bed file) into GenomeView (see below).

image:images/genomeview_trans.png["Transcript shown with predicted ORF", float="left"]


=== Viewing ORFs in the context of the transcript structures on the genome ===

[source,bash]
java -jar $GENOMEVIEW/genomeview.jar test.genome.fasta transcripts.bed transcripts.fasta.transdecoder.genome.bed

The original cufflinks-based transcript structures are shown in black, and the predicted coding regions are shown in cyan.


image:images/genomeview_cufflinks.png["Cufflinks trans in GenomeView with predicted ORFs", float="left"]


== Technical Support and Project Announcements ==

Subscribe to our mailing list at https://lists.sourceforge.net/lists/listinfo/transdecoder-users[https://lists.sourceforge.net/lists/listinfo/transdecoder-users].

Email us at transdecoder-users@lists.sf.net[mailto:transdecoder-users@lists.sf.net]

